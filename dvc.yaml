stages:
  ingest:
    cmd: Rscript pipeline/00-ingest.R
    desc: >
      Ingest training and assessment data from Athena + generate townhome
      complex identifiers
    params:
    - assessment
    - input
    outs:
    - input/training_data.parquet:
        cache: true
    - input/assessment_data.parquet:
        cache: true
    - input/complex_id_data.parquet:
        cache: true
    - input/land_site_rate_data.parquet:
        cache: true
    - input/land_nbhd_rate_data.parquet:
        cache: true
    frozen: true

  train:
    cmd: Rscript pipeline/01-train.R
    desc: >
      Train a LightGBM model with cross-validation. Generate model objects,
      data recipes, and predictions on the test set (most recent 10% of sales)
    deps:
    - input/training_data.parquet
    params:
    - toggle.cv_enable
    - cv
    - model.engine
    - model.objective
    - model.seed
    - model.verbose
    - model.predictor
    - model.parameter
    - model.hyperparameter.range
    outs:
    - output/parameter_final/model_parameter_final.parquet:
        cache: false
    - output/parameter_range/model_parameter_range.parquet:
        cache: false
    - output/parameter_search/model_parameter_search.parquet:
        cache: false
    - output/workflow/fit/model_workflow_fit.zip:
        cache: false
    - output/workflow/recipe/model_workflow_recipe.rds:
        cache: false
    - output/intermediate/timing/model_timing_train.parquet:
        cache: false
        
  assess:
    cmd: Rscript pipeline/02-assess.R
    desc: >
      Use the trained model to estimate sale prices for all PINS/cards in Cook
      County. Also generate flags, calculate land values, and make any
      post-modeling changes
    deps:
    - input/training_data.parquet
    - input/assessment_data.parquet
    - input/complex_id_data.parquet
    - input/land_site_rate_data.parquet
    - input/land_nbhd_rate_data.parquet
    - output/workflow/fit/model_workflow_fit.zip
    - output/workflow/recipe/model_workflow_recipe.rds
    params:
    - assessment
    - pv
    - ratio_study
    - model.predictor.all
    outs:
    - output/assessment_card/model_assessment_card.parquet:
        cache: false
    - output/assessment_pin/model_assessment_pin.parquet:
        cache: false
    - output/intermediate/model_assessment.parquet:
        cache: false
    - output/intermediate/timing/model_timing_assess.parquet:
        cache: false
        
  evaluate:
    cmd: Rscript pipeline/03-evaluate.R
    desc: >
      Evaluate the model's performance using two methods:
        1. The standard test set, in this case the most recent 10% of sales
        2. An assessor-specific ratio study comparing estimated assessments to
           the previous year's sales
    deps:
    - output/intermediate/model_test.parquet
    - output/intermediate/model_assessment.parquet
    params:
    - run_type
    - assessment.data_year
    - ratio_study
    outs:
    - output/performance/model_performance_test.parquet:
        cache: false
    - output/performance_quantile/model_performance_quantile_test.parquet:
        cache: false
    - output/performance/model_performance_assessment.parquet:
        cache: false
    - output/performance_quantile/model_performance_quantile_assessment.parquet:
        cache: false
    - output/intermediate/timing/model_timing_evaluate.parquet:
        cache: false
        
  interpret:
    cmd: Rscript pipeline/04-interpret.R
    desc: >
      Generate SHAP values for each card and feature in the assessment data
    deps:
    - input/assessment_data.parquet
    - output/workflow/fit/model_workflow_fit.zip
    - output/workflow/recipe/model_workflow_recipe.rds
    params:
    - model.predictor.all
    outs:
    - output/shap/model_shap.parquet:
        cache: false
    - output/intermediate/timing/model_timing_interpret.parquet:
        cache: false
        
  finalize:
    cmd: Rscript pipeline/05-finalize.R
    desc: >
       Save run timings, upload pipeline run results to S3, and send an SNS
       notification. Will also clean some of the generated outputs prior to
       upload and attach a unique run ID
    deps:
    - output/parameter_final/model_parameter_final.parquet
    - output/parameter_range/model_parameter_range.parquet
    - output/parameter_search/model_parameter_search.parquet
    - output/workflow/fit/model_workflow_fit.zip
    - output/workflow/recipe/model_workflow_recipe.rds
    - output/assessment_card/model_assessment_card.parquet
    - output/assessment_pin/model_assessment_pin.parquet
    - output/performance/model_performance_test.parquet
    - output/performance_quantile/model_performance_quantile_test.parquet
    - output/performance/model_performance_assessment.parquet
    - output/performance_quantile/model_performance_quantile_assessment.parquet
    - output/shap/model_shap.parquet
    - output/intermediate/timing/model_timing_train.parquet
    - output/intermediate/timing/model_timing_assess.parquet
    - output/intermediate/timing/model_timing_evaluate.parquet
    - output/intermediate/timing/model_timing_interpret.parquet
    params:
    - run_note
    - run_type
    - toggle
    - input
    - cv
    - model
    - pv
    - ratio_study
    outs:
    - output/timing/model_timing.parquet:
        cache: false
    - output/metadata/model_metadata.parquet:
        cache: false
