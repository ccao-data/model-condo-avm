---
title: "Valuation Summary"
author: "Cook County Assessor's Office"
date: "`r format(Sys.time(), '%d %B, %Y @ %r')`"
output: html_document
params:
  filter: "TRUE"
  triad: "City"
  assessment_year: 2021
---

```{r setup, include=FALSE}
# Load R libraries
library(arrow)
library(assessr)
library(ccao)
library(dplyr)
library(DT)
library(forcats)
library(ggplot2)
library(glue)
library(here)
library(lubridate)
library(purrr)
library(scales)
library(sf)
library(stringr)
library(tidyr)
options(tigris_use_cache = TRUE)

# Hide code output and make plots take 100% of page width
knitr::opts_chunk$set(echo = FALSE, out.width = '100%')

# Filter to specific triad. Set with system variable else param defined in yaml
report_filter <- as.logical(ccao::model_get_env("R_REPORT_FILTER", params$filter))

# Triad to use for report if filtered. Set with system variable else param
# defined in yaml
report_triad <- ccao::model_get_env("R_REPORT_TRIAD", params$triad)

# Set valuation parameters. Here we're setting the assessment year of the data
# This should be equal to the year of meta_sale_date in assmntdata
assessment_year <- as.numeric(model_get_env(
  "R_ASSESSMENT_YEAR", params$assessment_year
))

# Year of sales to attach to the final output data for the purpose of comparison
# and sales ratios studies. Typically the year prior to the assessment year
sales_ratio_year <- as.numeric(model_get_env(
  "R_SALES_RATIO_YEAR", assessment_year - 1
))

# Minimum year of sales to use to calculate post-modeling adjustment. Typically
# equal to assessment year - 3. We want 3 years worth of sales in order to get
# a large sample and counter any weirdness in the most recent year
sales_pv_min_year <- as.numeric(model_get_env(
  "R_SALES_PV_MIN_YEAR", assessment_year - 3
))
```

```{r load_data, include=FALSE}
# Load final assessment values from file (created by valuation.R). These include
# saved post-modeling adjusted values
pv_final_values <- read_parquet(
    here("output", "data", "finalvalues.parquet")
  ) %>%
  # Bed and breakfast and multi-code properties are excluded from reporting
  # because they are atypical and have inconsistently recorded sale prices
  filter(meta_modeling_group != "BB") %>%
  mutate(
    pri_board_est = meta_2yr_pri_board_est_bldg + meta_2yr_pri_board_est_land,
    certified_est = meta_certified_est_bldg + meta_certified_est_land,
    town_name = town_convert(meta_town_code),
    triad = factor(
      town_get_triad(meta_town_code, name = TRUE),
      levels = c("North", "City", "South")
    ),
    board_yoy_pct_change = (final_value - pri_board_est) / pri_board_est,
    certified_yoy_pct_change = (final_value - certified_est) / certified_est
  )

# For sales ratio studies, we want to keep only sales in the year prior to the
# assessment year
pv_final_values_fil <- pv_final_values %>% 
  mutate(meta_sale_price = ifelse(
    lubridate::year(meta_sale_date) >= sales_ratio_year,
    meta_sale_price,
    NA
  ))

# Load full sales data for use in reporting historical sales ratios and
# recreating post-modeling
sales_data <- read_parquet(here("input", "modeldata.parquet")) %>%
  group_by(meta_pin, meta_year) %>%
  filter(meta_sale_date == max(meta_sale_date)) %>%
  ungroup() %>%
  select(
    meta_pin, meta_year, meta_town_code, meta_class,
    meta_document_num, meta_sale_date, meta_sale_price
  ) %>%
  mutate(triad = town_get_triad(meta_town_code, name = TRUE))

# Filter data to specific triad based on report parameters
if (report_filter) {
  pv_final_values <- pv_final_values %>%
    filter(triad == report_triad)
  
  pv_final_values_fil <- pv_final_values_fil %>%
    filter(triad == report_triad)
  
  sales_data <- sales_data %>%
    filter(triad == report_triad)
}
```

## Overall Performance by Triad

```{r model_perf_triad, message=FALSE}
# Create overall performance table of standard sales ratio study stats
# To conform to SOPs, we need to use lagged sales for all years prior to the
# reporting/current year. See wiki SOPs section
sales_data_wide <- sales_data %>%
  filter(meta_year >= assessment_year - 4) %>%
  ungroup() %>%
  mutate(meta_year = case_when(
    meta_year == assessment_year - 1 ~ "yr-1",
    meta_year == assessment_year - 2 ~ "yr-2",
    meta_year == assessment_year - 3 ~ "yr-3",
    meta_year == assessment_year - 4 ~ "yr-4"
  )) %>%
  pivot_wider(
    id_cols = c(meta_pin, meta_class),
    names_from = meta_year,
    values_from = meta_sale_price,
    names_prefix = "sale_price_"
  )

# Wrapper function for calculating COD, PRD, PRB, and median ratio by group
# These performance stats are trimmed in accordance with CCAO SOPs
pv_calc_stats <- function(data) {
  data %>%
  summarize(
    bor_cod = list(ccao_cod(pri_board_est / `sale_price_yr-4`, na.rm = TRUE)),
    bor_prd = list(ccao_prd(pri_board_est, `sale_price_yr-4`, na.rm = TRUE)),
    bor_prb = list(ccao_prb(pri_board_est, `sale_price_yr-4`, na.rm = TRUE)),
    bor_med = median(pri_board_est / `sale_price_yr-4`, na.rm = TRUE),
    
    cert_cod = list(ccao_cod(certified_est / `sale_price_yr-2`, na.rm = TRUE)),
    cert_prd = list(ccao_prd(certified_est, `sale_price_yr-2`, na.rm = TRUE)),
    cert_prb = list(ccao_prb(certified_est, `sale_price_yr-2`, na.rm = TRUE)),
    cert_med = median(certified_est / `sale_price_yr-2`, na.rm = TRUE),
    
    init_cod = list(ccao_cod(lgbm_value / `sale_price_yr-1`, na.rm = TRUE)),
    init_prd = list(ccao_prd(lgbm_value, `sale_price_yr-1`, na.rm = TRUE)),
    init_prb = list(ccao_prb(lgbm_value, `sale_price_yr-1`, na.rm = TRUE)),
    init_med = median(lgbm_value / `sale_price_yr-1`, na.rm = TRUE),
    
    final_cod = list(ccao_cod(final_value / `sale_price_yr-1`, na.rm = TRUE)),
    final_prd = list(ccao_prd(final_value, `sale_price_yr-1`, na.rm = TRUE)),
    final_prb = list(ccao_prb(final_value, `sale_price_yr-1`, na.rm = TRUE)),
    final_med = median(final_value / `sale_price_yr-1`, na.rm = TRUE)
  ) %>%
  mutate(
    across(
      contains("_cod"),
      function(x) map_lgl(x, ~ any(cod_met(.x$COD_CI))), 
      .names = "{.col}_met"
    ),
    across(
      contains("_prd"),
      function(x) map_lgl(x, ~ any(prd_met(.x$PRD_CI))),
      .names = "{.col}_met"
    ),
    across(
      contains("_prb"),
      function(x) map_lgl(x, ~ any(prb_met(.x$PRB_CI))),
      .names = "{.col}_met"
    ),    
    across(ends_with("_med"), ~ between(.x, 0.95, 1.05), .names = "{.col}_met"),
    across(ends_with("_cod"), function(x) map_dbl(x, ~ .x$COD)),
    across(ends_with("_prd"), function(x) map_dbl(x, ~ .x$PRD)),
    across(ends_with("_prb"), function(x) map_dbl(x, ~ .x$PRB))
  )
}


# Calculate performance stats by triad
pv_model_perf_triad <- pv_final_values %>%
  left_join(
    sales_data_wide,
    by = c("meta_pin", "meta_class")
  ) %>%
  filter(pri_board_est != 0, certified_est != 0) %>%
  group_by(triad) %>%
  pv_calc_stats()

# Create a container with custom column headers for triad summary table
pv_model_perf_headers <- htmltools::withTags(table(
  class = "display", 
  thead(
    tr(
      th(rowspan = 2, "Township"),
      th(colspan = 4, glue(
        "BoR ({assessment_year - 3}) / {assessment_year - 4} Sales"
      )),
      th(colspan = 4, glue(
        "Certified ({assessment_year - 1}) / {assessment_year - 2} Sales"
      )),
      th(colspan = 4, glue(
        "Initial Model / {assessment_year - 1} Sales"
      )),
      th(colspan = 4, glue(
        "Final Model / {assessment_year - 1} Sales"
      )),
    ),
    tr(
      th("COD"), th("PRD"), th("PRB"), th("Med."),
      th("COD"), th("PRD"), th("PRB"), th("Med."),
      th("COD"), th("PRD"), th("PRB"), th("Med."),
      th("COD"), th("PRD"), th("PRB"), th("Med.")
    )
  )
))

# Create an interactive HTML table with all triad sales ratio stats
pv_model_perf_triad %>%
  datatable(
    rownames = FALSE,
    filter = "none",
    selection = "none",
    escape = FALSE,
    container = pv_model_perf_headers,
    options = list(
      scrollX = TRUE,
      autoWidth = TRUE,
      paging = FALSE,
      searching = FALSE,
      info = FALSE,
      columnDefs = list(list(targets = 17:32, visible = FALSE))
    )
  ) %>%
  formatRound(2:17, digits = 2) %>%
  formatStyle(  
    pv_model_perf_triad %>% select(2:17) %>% names() %>% sort(),
    pv_model_perf_triad %>% select(18:33) %>% names() %>% sort(),
    backgroundColor = styleEqual(
      c(0, 1),
      c("transparent", "#81ca9c")
    )
  )
```

<br>

## Overall Performance by Township

```{r model_perf_town, message=FALSE}
# Calculate sales ratio performance stats by township
pv_model_perf_township <- pv_final_values %>%
  left_join(
    sales_data_wide,
    by = c("meta_pin", "meta_class")
  ) %>%
  filter(pri_board_est != 0, certified_est != 0) %>%
  group_by(town_name) %>%
  pv_calc_stats()

# Create an interactive datatable with all stats by township
pv_model_perf_township %>%
  datatable(
    rownames = FALSE,
    filter = "none",
    selection = "none",
    escape = FALSE,
    container = pv_model_perf_headers,
    options = list(
      scrollX = TRUE,
      autoWidth = TRUE,
      paging = FALSE,
      searching = FALSE,
      info = FALSE,
      columnDefs = list(list(targets = 17:32, visible = FALSE))
    )
  ) %>%
  formatRound(2:17, digits = 2) %>%
  formatStyle(  
    pv_model_perf_township %>% select(2:17) %>% names() %>% sort(),
    pv_model_perf_township %>% select(18:33) %>% names() %>% sort(),
    backgroundColor = styleEqual(
      c(0, 1),
      c("transparent", "#81ca9c")
    )
  )
```

<br>

## Summary of Changes

```{r val_summary, message=FALSE}
# Goal here is to summarize YoY changes in terms of median values and percentage
# changes in value from year to year
pv_summary <- pv_final_values_fil %>%
  group_by(town_name) %>%
  summarize(
    triad = first(triad),
    num_props = n(),
    num_sales = sum(!is.na(meta_sale_price)),
    median_board_est = median(pri_board_est, na.rm = TRUE),
    median_certified_est = median(certified_est, na.rm = TRUE),
    median_sale_price = median(meta_sale_price, na.rm = TRUE),
    median_model_value = median(lgbm_value, na.rm = TRUE),
    median_final_value = median(final_value, na.rm = TRUE),
    med_yoy_pct_change_board = median(board_yoy_pct_change, na.rm = T),
    med_yoy_pct_change_cert = median(certified_yoy_pct_change, na.rm = T)
  )

# Create a container with custom column headers for summary table
pv_summary_headers <- htmltools::withTags(table(
  class = "display", 
  thead(
    tr(
      th(rowspan = 2, "Township"),
      th(rowspan = 2, "Triad"),
      th(rowspan = 2, "Num. Props"),
      th(rowspan = 2, glue("Num. Sales ({assessment_year - 1})")),
      th(colspan = 8, "Median Values"),
    ),
    tr(
      th(glue("BoR Value ({assessment_year - 3})")),
      th(glue("Certified Value ({assessment_year - 1})")),
      th(glue("Sale Price ({assessment_year - 1})")),
      th("Initial Model Value"),
      th("Final Model Value"),
      th("Median Percent Change (BoR to Final)"),
      th("Median Percent Change (Cert to Final)")
    )
  )
))

# Create an interactive table of the valuation summary results by township
pv_summary %>%
  datatable(
    rownames = FALSE,
    filter = "none",
    selection = "none",
    container = pv_summary_headers,
    escape = FALSE,
    options = list(
      autoWidth = TRUE,
      paging = FALSE,
      searching = FALSE,
      info = FALSE
    )
  ) %>%
  formatRound(3:4, digits = 0) %>%
  formatCurrency(c(5:9), digits = 0) %>%
  formatPercentage(c(10, 11), digits = 1)
```

<br>

## Map of Median Percent Change by Census Tract

```{r val_map, warning=FALSE, message=FALSE, fig.width=9, fig.height=9, results='hide'}
# Summarize YoY changes at the census tract level, both from the initial model
# value and the final model value
pv_summary_nbhd <- pv_final_values_fil %>%
  group_by(meta_nbhd) %>%
  summarize(
    med_yoy_pct_change_board = median(board_yoy_pct_change, na.rm = T),
    med_yoy_pct_change_cert = median(certified_yoy_pct_change, na.rm = T),
    med_yoy_pct_change_l_to_b = median(
      (lgbm_value - pri_board_est) / pri_board_est,
      na.rm = TRUE
    ),
    med_yoy_pct_change_l_to_c = median(
      (lgbm_value - certified_est) / certified_est,
      na.rm = TRUE
    )
  )

# Generate township-level map of YoY percent change for all finalized values
ccao::nbhd_shp %>%
  inner_join(pv_summary_nbhd, by = c("town_nbhd" = "meta_nbhd")) %>%
  pivot_longer(
    cols = c(med_yoy_pct_change_board:med_yoy_pct_change_l_to_c),
    names_to = "type",
    values_to = "change"
  ) %>%
  mutate(
    type = fct_recode(
      factor(type, levels = c(
        "med_yoy_pct_change_l_to_b",
        "med_yoy_pct_change_board", 
        "med_yoy_pct_change_l_to_c",
        "med_yoy_pct_change_cert"
      )),
      "BoR to Initial Model Value" = "med_yoy_pct_change_l_to_b",
      "BoR to Final Model Value" = "med_yoy_pct_change_board",
      "Certified to Initial Model Value" = "med_yoy_pct_change_l_to_c",
      "Certified to Final Model Value" = "med_yoy_pct_change_cert"
    )
  ) %>%
ggplot() +
  geom_sf(aes(fill = change, color = change, geometry = geometry)) +
  scale_fill_distiller(
    name = "Median\n% Change",
    palette = "Spectral",
    labels = scales::percent,
    direction = -1,
    limits = c(-0.75, 1.25)
  ) +
  scale_color_distiller(
    name = "Median\n% Change",
    palette = "Spectral",
    labels = scales::percent,
    direction = -1,
    limits = c(-0.75, 1.25)
  ) +
  facet_wrap(vars(type), nrow = 2) +
  theme_void() +
  theme(
    strip.text.x = element_text(size = 12),
    legend.title = element_text(margin = margin(b = 6))
  )
```

<br>

## Post-Modeling Settings

```{r post_model_settings, message=FALSE}
# Load the post-val model from file
pv_model <- readRDS(here("output", "models", "postval_model.rds"))

# Create markdown table of post-modeling settings
tibble(
  "Type" = c("N-Tile", "Townhome"),
  "Groups" = c(
    paste(pv_model$ntile_group_cols, collapse = ", "),
    paste(pv_model$townhome_group_cols, collapse = ", ")
  ),
  "Min. Sales" = c(
    pv_model$ntile_min_sales,
    pv_model$townhome_min_sales
  ),
  "Min. Turnover" = c(
    pv_model$ntile_min_turnover,
    pv_model$townhome_min_turnover
  ),
  "Max Pct. Adj." = c(
    pv_model$ntile_max_abs_adj,
    pv_model$townhome_max_abs_adj    
  ),
  "Cuts" = c(paste(pv_model$ntile_probs, collapse = ", "), "")
) %>%
  knitr::kable(format = "markdown")
```

<br>

## Post-Modeling Adjustment Results by Town

```{r post_model1, message=FALSE}
## Goal of this chunk is to recreate what happens in the post-modeling step-by-
# step, so that we can see the effect of each step independently and confirm
# that the adjustments are doing what's expected

# The final values already contain the most recent sale in the past 2 years, so
# we can just start by joining the ntiles from the postmodel
pv_postmodel_vals <- pv_final_values %>%
  left_join(pv_model$ntiles) %>%
  mutate(ntile = ccao:::val_assign_ntile(lgbm_value, ntiles_lst))
  
# Filter extraneous columns, then join the adjustments by ntile from the postval
# model object
pv_postmodel_vals2 <- pv_postmodel_vals %>%
  left_join(pv_model$ntile_adjustments) %>%
  # Add the ntile adjustment to the unadjusted value, then cap ratio if a sale
  # exists
  mutate(
    value_ntile_adj = rowSums(
      data.frame(lgbm_value, lgbm_value * ntile_med_pct_adj),
      na.rm = TRUE
      ),
    value_cap_adj = ccao::val_limit_ratios(
      meta_sale_price,
      value_ntile_adj,
      lower = pv_model$ratio_cap_lower_bound,
      upper = pv_model$ratio_cap_upper_bound
    ),
  ) %>%
  
  # Join townhome adjustments and overwrite ntile adjustments for townhomes only
  left_join(pv_model$townhome_adjustments) %>%
  mutate(
    value_th_adj = ifelse(
      !is.na(th_final_value),
      th_final_value,
      value_cap_adj
    ),
    diff = value_th_adj != final_value
  ) %>%
  select(
    meta_pin, meta_town_code, meta_nbhd, meta_class, meta_modeling_group, triad,
    town_name, th_med_pct_adj, th_num_sales, th_final_value, 
    ntiles_lst, ntile, ntile_med_pct_adj, ntile_num_props, ntile_num_sales,
    meta_sale_price, lgbm_value, value_ntile_adj, value_cap_adj, value_th_adj,
    final_value, diff
  )

# For each step in the process, count the number of changes that occurred from
# the previous step
pv_postmodel_summary <- pv_postmodel_vals2 %>%
  group_by(town_name) %>%
  summarize(
    num_props = n(),
    num_adj_total = sum(lgbm_value != final_value),
    pct_adj = num_adj_total / num_props,
    num_sales = sum(!is.na(meta_sale_price)),
    num_sales_adj = sum(lgbm_value != final_value & !is.na(meta_sale_price)),
    pct_sales_adj = num_sales_adj / num_sales,
    num_adj_by_ntile = sum(lgbm_value != value_ntile_adj),
    num_adj_by_cap = sum(value_ntile_adj != value_cap_adj),
    num_adj_by_th = sum(th_final_value == value_th_adj, na.rm = TRUE)
  )

# Create HTML header for summary table
pv_postmodel_headers <- htmltools::withTags(table(
  class = "display", 
  thead(
    tr(
      th(rowspan = 2, "Township"),
      th(colspan = 3, "All Props."),
      th(colspan = 3, "Sales"),
      th(colspan = 3, "Number of Adjustments"),
    ),
    tr(
      th("Total"), th("# Adj."), th("% Adj."),
      th("Total"), th("# Adj."), th("% Adj."),
      th("N-Tile"), th("Capped"), th("Townhome")
    )
  )
))

# Create interactive datatable
pv_postmodel_summary %>%
  datatable(
    rownames = FALSE,
    filter = "none",
    selection = "none",
    container = pv_postmodel_headers,
    escape = FALSE,
    options = list(
      autoWidth = TRUE,
      paging = FALSE,
      searching = FALSE,
      info = FALSE
    )
  ) %>%
  formatRound(c(2, 3, 5, 6, 8:10), digits = 0) %>%
  formatPercentage(c(4, 7), digits = 0)

# Stop the report if there are differences between the final value saved in
# finalvalues.parquet and the final value recreated with post-modeling in this
# chunk
if (sum(pv_postmodel_vals2$diff)) {
  stop("Found differences between post-modeling results and report results")
}
```

<br>

## Overall Ratio Distributions

```{r ratio_dist, warning=FALSE, message=FALSE}
# Plot histogram of ratios by modeling class (single-family vs multi-family)
# Ratios here are calculated using the last year of sales, not the three years
# used for post-modeling
pv_final_values_fil %>%
  mutate(
    meta_modeling_group = fct_recode(
      factor(meta_modeling_group, levels = c("SF", "MF", "NCHARS")),
      "Single-Family" = "SF",
      "Multi-Family" = "MF",
      "Condominiums" = "NCHARS"
  )) %>% 
  pivot_longer(c(lgbm_value, final_value)) %>%
  mutate(
    ratio = value / meta_sale_price,
    name = fct_recode(
      factor(name, levels = c("lgbm_value", "final_value")),
      "Initial Model Value" = "lgbm_value",
      "Final Model Value" = "final_value"
    )
  ) %>%
ggplot() +
  geom_histogram(aes(x = ratio, fill = name), binwidth = 0.05) +
  scale_x_continuous(breaks = breaks_extended(10), limits = c(0, 4)) +
  scale_fill_hue(name = "Ratio Type") +
  labs(
    x = "Sale Ratio",
    y = "Number of Properties"
  ) +
  facet_grid(vars(name), vars(meta_modeling_group)) +
  theme_minimal() +
  theme(
    legend.position = "bottom",
    strip.text = element_text(size = 12),
    axis.title.x = element_text(margin = margin(t = 6), size = 10),
    axis.title.y = element_text(margin = margin(r = 10), size = 10),
    panel.grid.minor = element_blank()
  ) +
  theme(
    strip.text = element_text(size = 12)
  )
```

<br>

## Price Density Distribution by Township

```{r value_dist, warning=FALSE, message=FALSE, results='hide'}
# Plot density of previous, predicted, adjusted value and sale price to look
# for discrepancies or oddities in distributions
pv_dist_vals <- pv_final_values_fil %>%
  pivot_longer(c(
    pri_board_est, certified_est, meta_sale_price,
    lgbm_value, final_value
  )) %>%
  mutate(name = fct_recode(
    factor(name, levels = c(
      "pri_board_est", "certified_est",
      "meta_sale_price", "lgbm_value", "final_value"
    )),
    "BoR Value (2 Years Ago)" = "pri_board_est",
    "Certified Value (Prior Year)" = "certified_est",
    "Sale Price (Prior Year)" = "meta_sale_price",
    "Initial Model Value" = "lgbm_value",
    "Final Model Value" = "final_value",
  ))

pv_dist_plot <- function(data) {
  data %>%
    ggplot() +
      geom_density(aes(x = value, color = name), size = 1.05) +
      scale_x_log10(
        limits = c(1e4, 2.5e6),
        labels = scales::dollar
      ) +
      labs(x = "Price (log scale)", y = "Density") +
      guides(color = guide_legend(title = "Value Source")) +
      facet_wrap(vars(town_name), ncol = 1) +
      theme_minimal()
}

# Split into a separate decile plot for every 2 townships, otherwise all
# townships would be in a single plot and would be squished
chunk <- function(x, n) split(x, sort(rank(x) %% n))
towns <- sort(unique(pv_dist_vals$town_name))
towns <- chunk(towns, ceiling(length(towns) / 2))

lapply(towns, function(chunk) pv_dist_plot(
  pv_dist_vals %>% filter(town_name %in% chunk)
))
```

<br>

## Ratio Distribution by Township by Sale Price Decile

```{r ratio_decile, warning=FALSE, message=FALSE, results='hide'}
# Split final values into decile by sale price, get count and distribution for
# each decile
decile_data_ratio <- pv_final_values_fil %>%
  filter(
    !is.na(meta_sale_price), !is.na(final_value),
    !is.na(lgbm_value)
  ) %>%
  mutate(
    decile = ntile(meta_sale_price, 10),
    across(c(lgbm_value, final_value), ~ .x / meta_sale_price)
  ) %>%
  group_by(decile) %>%
  mutate(decile_label = paste(
    dollar(min(meta_sale_price), 1, scale = 1/1000, suffix = "K"),
    dollar(max(meta_sale_price), 1, scale = 1/1000, suffix = "K"),
    sep = " - ")
  ) %>%
  ungroup() %>%
  mutate(decile_label = fct_rev(fct_reorder(factor(decile_label), decile))) %>%
  pivot_longer(
    c(lgbm_value, final_value),
    names_to = "name",
    values_to = "ratio"
  ) %>%
  mutate(
    name = fct_recode(
      factor(name, levels = c("final_value", "lgbm_value")),
      "Model Value" = "lgbm_value",
      "Final Value" = "final_value"
    )
  )

# Function to create decile plot based on a grouping variable. Goal is to show
# the shift in ratio distribution caused by post-modeling adjustment
decile_plot_ratio <- function(data, col_var) {
  
  data %>%
    group_by({{col_var}}, decile_label) %>%
    mutate(count = n()) %>%
  ggplot() +
    geom_boxplot(
      aes(x = ratio, color = name),
      outlier.alpha = 0.05
    ) +
    geom_text(
      aes(x = 3, y = 0, label = count),
      size = 3,
      hjust = 1,
      check_overlap = TRUE
    ) +
    scale_color_hue(name = "Ratio Type", direction = -1) +
    facet_grid(
      rows = vars(decile_label),
      cols = vars({{col_var}}),
      switch = "y"
    ) +
    xlim(0, 3) +
    labs(x = "Sale Ratio", y = "") +
    guides(color = guide_legend(reverse = TRUE)) +
    theme_minimal() +
    theme(
      legend.position = "bottom",
      axis.title.x = element_text(margin = margin(t = 10), size = 10),
      axis.text.y = element_blank(),
      panel.grid.major.y = element_blank(),
      panel.grid.minor.y = element_blank(),
      strip.text = element_text(size = 12),
      strip.text.y.left = element_text(angle = 0, hjust = 1),
      strip.text.x = element_text(margin = margin(b = 10)),
      panel.grid.minor = element_blank()
    )
}


# Split into a separate decile plot for every 4 townships, otherwise all
# townships would be in a single plot
chunk <- function(x, n) split(x, sort(rank(x) %% n))
towns <- sort(unique(decile_data_ratio$town_name))
towns <- chunk(towns, ceiling(length(towns) / 4))

lapply(towns, function(chunk) decile_plot_ratio(
  decile_data_ratio %>% filter(town_name %in% chunk),
  town_name
))

```

<br>

## Spatial Distribution of Largest YoY Changes (Certified to Final Model Value)

```{r outlier_map, message=FALSE}
# Create a township level map showing the location of the largest YoY percentage
# changes. Goal is to look for patterns of changes
pv_final_values_fil %>%
  filter(!is.infinite(certified_yoy_pct_change)) %>%
  mutate(
    dir = ifelse(certified_yoy_pct_change > 0, "Increase", "Decrease"),
    outlier = is_outlier(
      certified_yoy_pct_change,
      method = "quantile",
      probs = c(0.005, 0.995),
      na.rm = TRUE
    )
  ) %>%
  filter(outlier) %>%
  mutate(decile_label = cut(
    x = certified_yoy_pct_change,
    breaks = c(-Inf, -1, -0.5, 0, 0.5, 1, 1.5, 2, 2.5, 3, 3.5, 4, Inf),
    labels = c(
      "< -100%", "-100% to -50%", "-50% to 0%", "0% to 50%", "50% to 100%",
      "100% to 150%", "150% to 200%", "200% to 250%", "250% to 300%",
      "300% to 350%", "350% to 400%", "> 400%"
    )
  )) %>%
  ungroup() %>%
  st_as_sf(coords = c("geo_longitude", "geo_latitude"), crs = 4326) %>%
ggplot() +
  geom_sf(data = town_shp %>% filter(township_name %in% pv_final_values$town_name)) +
  geom_sf(
    aes(geometry = geometry, color = fct_rev(decile_label)),
    size = 0.7,
    alpha = 0.7
  ) +
  guides(color = guide_legend(title = "YoY % Change")) +
  facet_wrap(vars(dir)) +
  theme_void() +
  theme(
    strip.text = element_text(size = 12)
  )

```

<br>

## Distribution of YoY Percent Change by Township by Final Value Decile

```{r yoy_decile, warning=FALSE, message=FALSE, results='hide'}
# Split YoY percent change by BoR value
decile_data_yoy <- pv_final_values_fil %>%
  filter(
    !is.na(board_yoy_pct_change), !is.na(pri_board_est), pri_board_est != 0,
    !is.na(certified_yoy_pct_change), !is.na(certified_est), certified_est != 0
  ) %>%
  mutate(decile = ntile(final_value, 10)) %>%
  group_by(decile) %>%
  mutate(decile_label = paste(
    dollar(min(final_value), 1, scale = 1/1000, suffix = "K"),
    dollar(max(final_value), 1, scale = 1/1000, suffix = "K"),
    sep = " - ")
  ) %>%
  ungroup() %>%
  mutate(decile_label = fct_rev(fct_reorder(factor(decile_label), decile))) %>%
  pivot_longer(
    c(board_yoy_pct_change, certified_yoy_pct_change),
    names_to = "name",
    values_to = "value"
  ) %>%
  mutate(
    name = case_when(
      name == "board_yoy_pct_change" ~ glue(
        "BoR ({assessment_year - 4}) to Final Model"
      ),
      name == "certified_yoy_pct_change" ~ glue(
        "Cert. ({assessment_year - 1}) to Final Model"
      )
    ),
    name = factor(name, levels = c(
      glue("Cert. ({assessment_year - 1}) to Final Model"),
      glue("BoR ({assessment_year - 4}) to Final Model")
    ))
  )

# Function to create decile plot based on a grouping variable
decile_plot_yoy <- function(data, col_var) {
  
  data %>%
    group_by({{col_var}}, decile_label) %>%
    mutate(count = n()) %>%
  ggplot() +
    geom_boxplot(
      aes(x = value, color = name),
      outlier.shape = NA
    ) +
    geom_text(
      aes(x = 2, y = 0, label = count),
      size = 3,
      hjust = 1,
      check_overlap = TRUE
    ) +
    scale_x_continuous(labels = scales::percent, limits = c(-1, 2)) +
    scale_color_hue(name = "", direction = -1) +
    facet_grid(
      rows = vars(decile_label),
      cols = vars({{col_var}}),
      switch = "y"
    ) +
    labs(x = "% Change", y = "") +
    guides(color = guide_legend(reverse = TRUE)) +
    theme_minimal() +
    theme(
      legend.position = "bottom",
      axis.title.x = element_text(margin = margin(t = 10), size = 10),
      axis.text.y = element_blank(),
      axis.text.x = element_text(angle = -45, hjust = 0),
      panel.grid.major.y = element_blank(),
      panel.grid.minor.y = element_blank(),
      strip.text = element_text(size = 12),
      strip.text.y.left = element_text(angle = 0, hjust = 1),
      strip.text.x = element_text(margin = margin(b = 10)),
      panel.grid.minor = element_blank()
    )
}


# Split into a separate decile plot for every 4 townships
chunk <- function(x, n) split(x, sort(rank(x) %% n))
towns <- sort(unique(decile_data_yoy$town_name))
towns <- chunk(towns, ceiling(length(towns) / 4))

lapply(towns, function(chunk) decile_plot_yoy(
  decile_data_yoy %>% filter(town_name %in% chunk),
  town_name
))
```

