# - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
##### Setup ####
# - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -

# Load R libraries
library(arrow)
library(assessr)
library(beepr)
library(ccao)
library(dplyr)
library(here)
library(purrr)
library(recipes)
library(stringr)
library(tictoc)
library(tidymodels)
library(treesnip)

# Start full script timer
tictoc::tic(msg = "Full Valuation Complete!")

# Set valuation parameters. Here we're setting the assessment year of the data
# This should be equal to the year of meta_sale_date in assmntdata
assessment_year <- as.numeric(model_get_env(
  "R_ASSESSMENT_YEAR", lubridate::year(Sys.Date())
))

# Minimum year of sales to use to calculate post-modeling adjustment. Typically
# equal to assessment year - 3. We want 3 years worth of sales in order to get
# a large sample and counter any weirdness in the most recent year
sales_pv_min_year <- as.numeric(model_get_env(
  "R_SALES_PV_MIN_YEAR", assessment_year - 3
))




# - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
##### Valuation ####
# - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -

# Load the final lightgbm model object and recipe from file
lgbm_final_full_fit <- ccao::model_lgbm_load(
  here("output", "models", "lgbm_model.zip")
)
lgbm_final_full_recipe <- readRDS(
  here("output", "models", "lgbm_recipe.rds")
)

# Post-modeling adjustments (such as ratio capping) require sales to work.
# As such, we need to append the most recent sale (closest to the assessment
# date within 3 years) to each PIN. Not all PINs will have sales, as our overall
# sales sample is limited to 7 years prior to the assessment date
sales_data_prev_3_years <- read_parquet(here("input", "modeldata.parquet")) %>%
  filter(meta_year >= sales_pv_min_year) %>%
  group_by(meta_pin) %>%
  filter(meta_sale_date == max(meta_sale_date)) %>%
  distinct(meta_pin, meta_sale_price, meta_sale_date, meta_document_num) %>%
  ungroup()

# Load the full set of residential properties that need values, join the sales
# where available
assmntdata <- read_parquet(here("input", "assmntdata.parquet")) %>%
  select(-meta_sale_date) %>%
  left_join(sales_data_prev_3_years, by = "meta_pin")

# Generate predictions for all assessment data using the lightgbm model created
# in model.R
assmntdata <- assmntdata %>%
  mutate(
    lgbm_value = ccao::model_predict(
      spec = lgbm_final_full_fit,
      recipe = lgbm_final_full_recipe,
      data = .
    )
  ) 




# - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
##### Post-Valuation Model ####
# - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -

# To correct for model and data bias, we implement an additional post-modeling
# process which attempts to correct skew, fix outliers, etc. The adjustments
# generate an additional model object which must also be applied to new data
# in order to get final, first-pass model values

# Create post-valuation model object to save aggregate adjustments. Townhome
# adjustments are ignored here
pv_model <- ccao::postval_model(
  data = assmntdata,
  truth = meta_sale_price,
  estimate = lgbm_value,
  class = meta_class,
  ntile_group_cols = c("meta_town_code"),
  ntile_probs = seq(0.1, 0.9, 0.1),
  ntile_min_sales = 30,
  ntile_min_turnover = 0.13,
  ntile_max_abs_adj = 0.4,
  townhome_group_cols = c("meta_town_code"),
  townhome_min_sales = 3,
  townhome_min_turnover = 1,
  townhome_max_abs_adj = 0.4,
  ratio_cap_upper_bound = 2.0,
  ratio_cap_lower_bound = 0.7
)

# Save postval model to file so it can be used for any future predictions
pv_model %>%
  saveRDS(here("output", "models", "postval_model.rds"))

# Applied the postval model to initial lightgbm predictions to get final
# predicted values. Keep only the columns needed for final output
pv_final_values <- assmntdata %>%
  mutate(
    final_value = predict(
      object = pv_model,
      new_data = .,
      truth = meta_sale_price,
      estimate = lgbm_value
    )
  )

# Save final values to file so they can be uploaded to AS/400 or Tyler iasWorld
pv_final_values %>%
  ccao::recp_clean_relocate() %>%
  write_parquet(here("output", "data", "finalvalues.parquet"))


### Generate reports

# Generate valuation performance/diagnostic report
rmarkdown::render(
  input = here("reports", "valuation_report.Rmd"),
  output_file = here("output", "reports", "valuation_report.html")
)

# Stop full script timer
tictoc::toc()

# BIG BEEP
beepr::beep(8)
